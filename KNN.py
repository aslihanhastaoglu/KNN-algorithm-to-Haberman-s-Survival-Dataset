# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I-j7SKjlwpQUIwB79EE9q2gOVNeehk0Y
"""

from csv import reader
import math
from math import sqrt
from random import seed
from random import randrange

def euclidian_dist(p1, p2):
    dim, sum_ = len(p1), 0
    for index in range(dim - 1):
        sum_ += math.pow(p1[index] - p2[index], 2)
    return math.sqrt(sum_)

def k_neighbors(train, test_row, num_neighbors):
	distances = list()
	for train_row in train:
		dist = euclidian_dist(test_row, train_row)
		distances.append((train_row, dist))
	distances.sort(key=lambda tup: tup[1])
	neighbors = list()
	for i in range(num_neighbors):
		neighbors.append(distances[i][0])
	return neighbors

# sınıflandırma
def classify(train, test_row, num_neighbors):
	neighbors =k_neighbors(train, test_row, num_neighbors)
	output_values = [row[-1] for row in neighbors]
	prediction = max(set(output_values), key=output_values.count)
	return prediction

def accuracy_metric(actual, predicted):
	correct = 0
	for i in range(len(actual)):
		if actual[i] == predicted[i]:
			correct += 1
	return correct / float(len(actual)) * 100.0

# kNN Algorithma
def knn(train, test, num_neighbors):
	predictions = list()
	for row in test:
		output = classify(train, row, num_neighbors)
		predictions.append(output)
	return(predictions)

def cross_validation_split(dataset, n_folds):
	dataset_split = list()
	dataset_copy = list(dataset)
	fold_size = int(len(dataset) / n_folds)
	for _ in range(n_folds):
		fold = list()
		while len(fold) < fold_size:
			index = randrange(len(dataset_copy))
			fold.append(dataset_copy.pop(index))
		dataset_split.append(fold)
	return dataset_split


def evaluate(dataset, algorithm, n_folds, *args):
	folds = cross_validation_split(dataset, n_folds)
	scores = list()
	for fold in folds:
		train_set = list(folds)
		train_set.remove(fold)
		train_set = sum(train_set, [])
		test_set = list()
		for row in fold:
			row_copy = list(row)
			test_set.append(row_copy)
			row_copy[-1] = None
		predicted = algorithm(train_set, test_set, *args)
		actual = [row[-1] for row in fold]
		accuracy = accuracy_metric(actual, predicted)
		scores.append(accuracy)
	return scores


filename = 'haberman1.csv'
dataset = list()
with open(filename, 'r') as file:
	csv_reader = reader(file)
	for row in csv_reader:
		if not row:
			continue
		dataset.append(row)

for i in range(len(dataset[0])-1):
	for row in dataset:
		row[i] = float(row[i].strip())

num_neighbors = 3
row = [30,65,5,2]
label = classify(dataset, row, num_neighbors)
print('Data=%s, Predicted: %s' % (row, label))

K_set = [3,5,7,10]
for K in K_set:
  accurancyScore = evaluate(dataset, knn, K, K);
  print("------------------------------")        
  print("K : %d" % K)
  print("Correct predicitons:", accurancyScore)
  print('Accuracy: %.2f%%' % (sum(accurancyScore)/float(len(accurancyScore))))